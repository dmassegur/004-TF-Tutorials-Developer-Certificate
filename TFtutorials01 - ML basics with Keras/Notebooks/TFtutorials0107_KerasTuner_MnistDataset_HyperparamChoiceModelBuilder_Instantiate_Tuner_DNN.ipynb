{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TFtutorials007_KerasTuner_MnistDataset_HyperparamChoiceModelBuilder_Instantiate_Tuner_DNN.ipynb","provenance":[{"file_id":"17tPaNjaRJyLYehfkObyUT4Y9MX9MOgfR","timestamp":1589902607578},{"file_id":"1gRw5TWtcA-aDFW-I9qDdr-WPItWIHwmp","timestamp":1589838652827},{"file_id":"1sm19pV1Nhq7-osKgH86e9NWyS0Ak7mar","timestamp":1589470992513},{"file_id":"1vGrWx_FukNmR_Ka9UWqztFv-l24AvjWN","timestamp":1589381852365},{"file_id":"1K1NuBRxHhXleVaTFU0pO70AMLF2hJQgH","timestamp":1589325455523},{"file_id":"1jTD51ta4hG7qGT2xNP6mCFmgBkEkjjsJ","timestamp":1588810591078},{"file_id":"1ddpr6dulGZXgKL3BFl1b60DQMcbN7N3x","timestamp":1588636278540},{"file_id":"1t474kLoxzgem1ernyGkNz6EV26WNMQa-","timestamp":1587597310400}],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyOkZZ9AyLC+Lmzu52FFID5h"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"m0rDiqQwLQSE","colab_type":"code","outputId":"991cc91c-9216-43e9-974a-015cc26f30e7","executionInfo":{"status":"ok","timestamp":1589928557716,"user_tz":-60,"elapsed":13853,"user":{"displayName":"David Massegur","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPdhI-xRflKGWfi6g6h7PuXGRiA48J_SQUfTBPGw=s64","userId":"15590998365704503071"}},"colab":{"base_uri":"https://localhost:8080/","height":301}},"source":["# TensorFlow Tutorials\n","# ML basics with Keras \n","# Keras Tuner\n","# https://www.tensorflow.org/tutorials/keras/keras_tuner\n","\n","# Keras tuner: https://keras-team.github.io/keras-tuner/\n","# Keras tuner blog: https://blog.tensorflow.org/2020/01/hyperparameter-tuning-with-keras-tuner.html\n","# Hyperband: https://arxiv.org/pdf/1603.06560.pdf\n","\n","# tfds reshufle: https://www.tensorflow.org/api_docs/python/tf/reshape\n","# TF.data.Dataset: https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n","# TF Keras: https://www.tensorflow.org/guide/keras\n","\n","# Using the SavedModel format: https://www.tensorflow.org/guide/saved_model#save_and_restore_variables\n","# Writing custome layers and models in keras: https://www.tensorflow.org/guide/keras/custom_layers_and_models\n","# HDF5: https://en.wikipedia.org/wiki/Hierarchical_Data_Format\n","\n","# Keras get file: https://www.tensorflow.org/api_docs/python/tf/keras/utils/get_file\n","# pd map: reassign values in a series: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.map.html\n","# pd get_dummies  to one-hot encode a categorical column: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html\n","# pd pop: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pop.html\n","# TF Keras EarlyStopping: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\n","# np expand dimension: https://docs.scipy.org/doc/numpy/reference/generated/numpy.expand_dims.html\n","# np collapse dimension: https://docs.scipy.org/doc/numpy/reference/generated/numpy.squeeze.html\n","\n","\n","# https://www.tensorflow.org/tutorials/structured_data/feature_columns\n","# https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n","\n","# mnist tfds dataset: https://www.tensorflow.org/datasets/catalog/mnist\n","\n","# tfds.load: https://www.tensorflow.org/datasets/api_docs/python/tfds/load\n","# TF Hub (Transfer Learning): https://www.tensorflow.org/hub\n","\n","# TF Keras Embedding: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n","# TF Hub Keraslayer: https://www.tensorflow.org/hub/api_docs/python/hub/KerasLayer\n","# TF Keras regularizers: https://keras.io/api/layers/regularizers/    https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/Regularizer\n","# TF Keras Cnv1D: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv1D\n","# TF Keras LSTM: https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM\n","# TF Keras Dense: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense\n","# TF Keras activation functions: https://keras.io/api/layers/activations/\n","\n","# Live training plots: https://gist.github.com/stared/dfb4dfaf6d9a8501cd1cc8b8cb806d2e\n","\n","\n","# Required to save models in HDF5 format\n","!pip install -q pyyaml h5py\n","\n","\n","\n","import pathlib\n","import shutil\n","import tempfile\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import IPython\n","\n","\n","import tensorflow as tf\n","print(tf.__version__)\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras import regularizers\n","\n","from IPython import display\n","from IPython.display import clear_output\n","# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import os\n","from datetime import *\n","\n","\n","!pip install -q -U keras-Tuner\n","import kerastuner as kt\n","\n","\n","# logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n","# shutil.rmtree(logdir, ignore_errors=True)\n","\n","# # Use seaborn for pairplot\n","# !pip install -q seaborn\n","\n","# # Use some functions from tensorflow_docs\n","# !pip install -q git+https://github.com/tensorflow/docs\n","\n","# import tensorflow_docs as tfdocs\n","# import tensorflow_docs.plots\n","# import tensorflow_docs.modeling\n","\n","\n","\n","print(\"TF Version: \", tf.__version__)\n","# print(\"Eager mode: \", tf.executing_eagerly())\n","# print(\"Hub version: \", hub.__version__)\n","print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")\n","\n","print('\\n')\n","\n","\n","starttime = datetime.now()\n","\n","\n","# Download the dataset:\n","(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n","# # Take the first 1000 examples:\n","# train_labels = train_labels[:1000]\n","# test_labels = test_labels[:1000]\n","\n","# print(train_images.shape)\n","\n","# # reshape(-1) flattens the image data.\n","# train_images = train_images[:1000].reshape(-1, 28*28) / 255.0\n","# test_images = test_images[:1000].reshape(-1, 28*28) / 255.0\n","\n","# train_images = train_images.take(1000)  #.reshape(-1, 28*28) / 255.0\n","\n","train_images = train_images.astype('float32') / 255.0\n","test_images = test_images.astype('float32') / 255.0\n","\n","print(train_images.shape)\n","\n","\n","\n","et1 = datetime.now() - starttime\n","\n","print( '\\n-> Elapsed execution time: %0.4f seconds.\\n' %(et1.total_seconds()) )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"},{"output_type":"stream","text":["2.2.0\n","\u001b[K     |████████████████████████████████| 61kB 1.8MB/s \n","\u001b[?25h  Building wheel for keras-Tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n","TF Version:  2.2.0\n","GPU is available\n","\n","\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","(60000, 28, 28)\n","\n","-> Elapsed execution time: 0.8102 seconds.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hZZ4ebeoM0rj","colab_type":"text"},"source":["## Define the model\n","\n","When you build a model for hypertuning, you also define the hyperparameter search space in addition to the model architecture. The model you set up for hypertuning is called a *hypermodel*.\n","\n","You can define a hypermodel through two approaches:\n","\n","* By using a model builder function\n","* By subclassing the `HyperModel` class of the Keras Tuner API\n","\n","You can also use two pre-defined `HyperModel` classes - [HyperXception](https://keras-team.github.io/keras-tuner/documentation/hypermodels/#hyperxception-class) and [HyperResNet](https://keras-team.github.io/keras-tuner/documentation/hypermodels/#hyperresnet-class) for computer vision applications.\n","\n","In this tutorial, you use a model builder function to define the image classification model. The model builder function returns a compiled model and uses hyperparameters you define inline to hypertune the model."]},{"cell_type":"code","metadata":{"id":"tHLg-QJ1M1o3","colab_type":"code","colab":{}},"source":["def model_builder(hp):\n","  model = keras.Sequential()\n","  model.add(keras.layers.Flatten(input_shape=(28, 28)))\n","  \n","  # Tune the number of units in the first Dense layer\n","  # Choose an optimal value between 32-512\n","  hp_units = hp.Int('units', min_value = 32, max_value = 512, step = 32)  # integer\n","  model.add(keras.layers.Dense(units = hp_units, activation = 'relu'))\n","  model.add(keras.layers.Dense(10))\n","\n","  # Tune the learning rate for the optimizer \n","  # Choose an optimal value from 0.01, 0.001, or 0.0001\n","  hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4])   # choice() is an inbuilt function in Python programming language that returns a random item from a list, tuple, or string.\n","  \n","  model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\n","                loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True), \n","                metrics = ['accuracy'])\n","  \n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1dLu7YAzqdI1","colab_type":"text"},"source":["## Instantiate the tuner and perform hypertuning\n","\n","Instantiate the tuner to perform the hypertuning. The Keras Tuner has four tuners available - `RandomSearch`, `Hyperband`, `BayesianOptimization`, and `Sklearn`. In this tutorial, you use the [Hyperband](https://arxiv.org/pdf/1603.06560.pdf) tuner. \n","\n","To instantiate the Hyperband tuner, you must specify the hypermodel, the `objective` to optimize and the maximum number of epochs to train (`max_epochs`)"]},{"cell_type":"code","metadata":{"id":"vDMij5SGrTYD","colab_type":"code","colab":{}},"source":["tuner = kt.Hyperband(model_builder,\n","                     objective = 'val_accuracy', \n","                     max_epochs = 10,\n","                     factor = 3,\n","                     directory = 'my_dir',\n","                     project_name = 'intro_to_kt')    "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OYymI-8gsAiN","colab_type":"text"},"source":["The Hyperband tuning algorithm uses adaptive resource allocation and early-stopping to quickly converge on a high-performing model. This is done using a sports championship style bracket. The algorithm trains a large number of models for a few epochs and carries forward only the top-performing half of models to the next round. Hyperband determines the number of models to train in a bracket by computing 1 + log<sub>`factor`</sub>(`max_epochs`) and rounding it up to the nearest integer.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8RTAASSHsFw0","colab_type":"text"},"source":["Before running the hyperparameter search, define a callback to clear the training outputs at the end of every training step."]},{"cell_type":"code","metadata":{"id":"n-WaBWPZsKZw","colab_type":"code","colab":{}},"source":["class ClearTrainingOutput(tf.keras.callbacks.Callback):\n","  def on_train_end(*args, **kwargs):\n","    IPython.display.clear_output(wait = True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZxWdNTaisMu_","colab_type":"text"},"source":["Run the hyperparameter search. The arguments for the search method are the same as those used for `tf.keras.model.fit` in addition to the callback above."]},{"cell_type":"code","metadata":{"id":"REzys1FOH11o","colab_type":"code","outputId":"10e2bd81-0794-4201-f39f-57a0f72e2e0a","executionInfo":{"status":"ok","timestamp":1589929294095,"user_tz":-60,"elapsed":438808,"user":{"displayName":"David Massegur","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPdhI-xRflKGWfi6g6h7PuXGRiA48J_SQUfTBPGw=s64","userId":"15590998365704503071"}},"colab":{"base_uri":"https://localhost:8080/","height":435}},"source":["starttime = datetime.now()\n","\n","\n","tuner.search(train_images, train_labels, epochs = 10, validation_data = (test_images, test_labels), callbacks = [ClearTrainingOutput()])\n","\n","# Get the optimal hyperparameters\n","best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n","\n","print(f\"\"\"\n","The hyperparameter search is complete. The optimal number of units in the first densely-connected\n","layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n","is {best_hps.get('learning_rate')}.\n","\"\"\")\n","\n","\n","et1 = datetime.now() - starttime\n","\n","print( '\\n-> Elapsed execution time: %0.4f seconds.\\n' %(et1.total_seconds()) )"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Trial ID: 2873e2a89b5c033d4e7f17cda5f7bc9c</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Score: 0.9821000099182129</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-Best step: 0</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:blue\"> |-tuner/bracket: 0</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-tuner/epochs: 10</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:blue\"> |-tuner/initial_epoch: 0</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:cyan\"> |-tuner/round: 0</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<span style=\"color:blue\"> |-units: 480</span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["INFO:tensorflow:Oracle triggered exit\n","\n","The hyperparameter search is complete. The optimal number of units in the first densely-connected\n","layer is 480 and the optimal learning rate for the optimizer\n","is 0.001.\n","\n","\n","-> Elapsed execution time: 438.0620 seconds.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_CIN6ymyKnnt","colab_type":"text"},"source":["To finish this tutorial, retrain the model with the optimal hyperparameters from the search."]},{"cell_type":"code","metadata":{"id":"eaMhpCx3KqWp","colab_type":"code","outputId":"e714a700-2ea2-43e3-eebe-5a1739c93f72","executionInfo":{"status":"ok","timestamp":1589929391803,"user_tz":-60,"elapsed":36606,"user":{"displayName":"David Massegur","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPdhI-xRflKGWfi6g6h7PuXGRiA48J_SQUfTBPGw=s64","userId":"15590998365704503071"}},"colab":{"base_uri":"https://localhost:8080/","height":425}},"source":["starttime = datetime.now()\n","\n","\n","# Build the model with the optimal hyperparameters and train it on the data\n","model = tuner.hypermodel.build(best_hps)\n","model.fit(train_images, train_labels, epochs = 10, validation_data = (test_images, test_labels))\n","\n","\n","et1 = datetime.now() - starttime\n","\n","print( '\\n-> Elapsed execution time: %0.4f seconds.\\n' %(et1.total_seconds()) )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2009 - accuracy: 0.9410 - val_loss: 0.1075 - val_accuracy: 0.9649\n","Epoch 2/10\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.0799 - accuracy: 0.9762 - val_loss: 0.0907 - val_accuracy: 0.9715\n","Epoch 3/10\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.0523 - accuracy: 0.9835 - val_loss: 0.0692 - val_accuracy: 0.9792\n","Epoch 4/10\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.0348 - accuracy: 0.9888 - val_loss: 0.0690 - val_accuracy: 0.9802\n","Epoch 5/10\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.0288 - accuracy: 0.9906 - val_loss: 0.0688 - val_accuracy: 0.9795\n","Epoch 6/10\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.0202 - accuracy: 0.9934 - val_loss: 0.0677 - val_accuracy: 0.9813\n","Epoch 7/10\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.0185 - accuracy: 0.9933 - val_loss: 0.0676 - val_accuracy: 0.9823\n","Epoch 8/10\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.0141 - accuracy: 0.9952 - val_loss: 0.0663 - val_accuracy: 0.9833\n","Epoch 9/10\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 0.0804 - val_accuracy: 0.9790\n","Epoch 10/10\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.0685 - val_accuracy: 0.9825\n","\n","-> Elapsed execution time: 35.4043 seconds.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7srWqgYoK0hS","colab_type":"text"},"source":["The `my_dir/intro_to_kt` directory contains detailed logs and checkpoints for every trial (model configuration) run during the hyperparameter search. If you re-run the hyperparameter search, the Keras Tuner uses the existing state from these logs to resume the search. To disable this behavior, pass an additional `overwrite = True` argument while instantiating the tuner."]},{"cell_type":"code","metadata":{"id":"7zg8WbgULp-L","colab_type":"code","outputId":"a356e4a3-6cbb-404c-f6e3-4d7cb880d907","executionInfo":{"status":"ok","timestamp":1589929681364,"user_tz":-60,"elapsed":9290,"user":{"displayName":"David Massegur","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPdhI-xRflKGWfi6g6h7PuXGRiA48J_SQUfTBPGw=s64","userId":"15590998365704503071"}},"colab":{"base_uri":"https://localhost:8080/","height":410}},"source":["!ls\n","print(os.listdir(os.getcwd()))\n","\n","!ls my_dir\n","print(os.listdir('my_dir'))\n","\n","!ls my_dir/intro_to_kt\n","print(os.listdir('my_dir/intro_to_kt'))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["my_dir\tsample_data\n","['.config', 'my_dir', 'sample_data']\n","intro_to_kt\n","['intro_to_kt']\n","oracle.json\t\t\t\ttrial_74e793cec9551e9b31d000f97eb706ef\n","trial_00efc3c1773bb05a0945ea3d6f0e2562\ttrial_78f17e53b3a4c200596c30533dd0cdb3\n","trial_0362abddd2772c852d21be660d9e1632\ttrial_89f4dd07f3a98042cd0b2ce1fba0b897\n","trial_0ebda25ec47cf6e8904e94fa40cb65b4\ttrial_8f9bddcf34ecce27c933ade34c25fe34\n","trial_0fc79fd6fdc6dae3e89a786fb16377da\ttrial_91bdd82b0a9081ce9d764b0211b15bc1\n","trial_270594691697be306ab0c9a1a66f66cd\ttrial_a2d8375206a51f8ca72026e9169532be\n","trial_2873e2a89b5c033d4e7f17cda5f7bc9c\ttrial_aa927269be380c89cb6a397273cfc824\n","trial_331203a387ca4d4c53dbcdd315e5db0c\ttrial_aaa7592e230b9555d5e51a6c39e1a540\n","trial_480ecfc216bac1502212304121536f48\ttrial_b7f7b8a13ad1620e4dfd0c3a5490508a\n","trial_4a2624920d60e7f96c089f81b044642b\ttrial_bb68b3357a004b5081d2d17cd91571c2\n","trial_4a74c86d5ff51cf1e0afb0781c804b0c\ttrial_c794a22f457f52332ed87eb6bf87b5cf\n","trial_4b5eff50efcf78e0a95e6dad19b45a5c\ttrial_c9491f16fab9909efd11fc5814e32511\n","trial_540a71e3a03b1913a0659c8c3be89ef9\ttrial_f3e8bcfd416d76e8c19e2a5025343bef\n","trial_5c61eb36292244a9a635806d844a6972\ttrial_f4abe0d720f553b97b24e09b2de8af2a\n","trial_6a854590a87d1a9072f62d17201cb353\ttrial_f4e66d3c223f06aea1036cd739d9f886\n","trial_71ead306a4b6fb87f2d076700aa49b6d\ttuner0.json\n","['trial_a2d8375206a51f8ca72026e9169532be', 'oracle.json', 'trial_540a71e3a03b1913a0659c8c3be89ef9', 'trial_270594691697be306ab0c9a1a66f66cd', 'trial_b7f7b8a13ad1620e4dfd0c3a5490508a', 'trial_aa927269be380c89cb6a397273cfc824', 'trial_6a854590a87d1a9072f62d17201cb353', 'trial_f4e66d3c223f06aea1036cd739d9f886', 'trial_74e793cec9551e9b31d000f97eb706ef', 'trial_0362abddd2772c852d21be660d9e1632', 'trial_480ecfc216bac1502212304121536f48', 'trial_00efc3c1773bb05a0945ea3d6f0e2562', 'trial_5c61eb36292244a9a635806d844a6972', 'trial_78f17e53b3a4c200596c30533dd0cdb3', 'trial_8f9bddcf34ecce27c933ade34c25fe34', 'trial_0fc79fd6fdc6dae3e89a786fb16377da', 'trial_4a74c86d5ff51cf1e0afb0781c804b0c', 'trial_331203a387ca4d4c53dbcdd315e5db0c', 'trial_4a2624920d60e7f96c089f81b044642b', 'trial_c9491f16fab9909efd11fc5814e32511', 'trial_c794a22f457f52332ed87eb6bf87b5cf', 'trial_0ebda25ec47cf6e8904e94fa40cb65b4', 'tuner0.json', 'trial_71ead306a4b6fb87f2d076700aa49b6d', 'trial_2873e2a89b5c033d4e7f17cda5f7bc9c', 'trial_89f4dd07f3a98042cd0b2ce1fba0b897', 'trial_bb68b3357a004b5081d2d17cd91571c2', 'trial_4b5eff50efcf78e0a95e6dad19b45a5c', 'trial_f3e8bcfd416d76e8c19e2a5025343bef', 'trial_aaa7592e230b9555d5e51a6c39e1a540', 'trial_91bdd82b0a9081ce9d764b0211b15bc1', 'trial_f4abe0d720f553b97b24e09b2de8af2a']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Gd3KPdr4K3QK","colab_type":"text"},"source":["## Summary\n","\n","In this tutorial, you learned how to use the Keras Tuner to tune hyperparameters for a model. To learn more about the Keras Tuner, check out these additional resources:\n","\n","* [Keras Tuner on the TensorFlow blog](https://blog.tensorflow.org/2020/01/hyperparameter-tuning-with-keras-tuner.html)\n","* [Keras Tuner website](https://keras-team.github.io/keras-tuner/)\n","\n","Also check out the [HParams Dashboard](https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams) in TensorBoard to interactively tune your model hyperparameters."]}]}
